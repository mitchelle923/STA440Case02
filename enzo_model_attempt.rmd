---
title: "Attempting a Model"
author: "Enzo Moraes Mescall"
date: "`r Sys.Date()`"
output: pdf_document
--- 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library(tidyverse)
library(invgamma)
library(fitdistrplus)
```

## Methodology Writeup

In this study, we present a Bayesian statistical Monte Carlo approach to select the top male and female American gymnast candidates for participation in the 2024 Olympics. Our method involves the creation of prior distributions based on historical performance data, conditioning these distributions on individual competition results, and simulating medal outcomes by predicting scores for each gymnast in each apparatus event. The approach offers a robust framework for incorporating both prior beliefs and observed data to make informed predictions about athletes' performances in simulated events (Hoff, 2009). Utilizing Bayes' law for probability density functions, where $x$ is a vector of all the data from an apparatus and gender combination, $x_i$ represents the vector of observed data for athlete $i$, and $\theta$ represents the parameters of the distribution we will be using to model the competition. We are under the assumption that all gymnastic scores are independent and identically distributed for every athlete and that every athlete's scores come from the same distribution type. Furthermore, for modeling purposes, we assume a common prior $p(x| \theta)$ for all athletes such that $p(x_i | \theta) = p(x| \theta)$ for all $i$. This allows us to write the posterior distribution as:

$$
p(\theta |x_i) \propto p(x| \theta) p(\theta)
$$

To simulate a score for an athlete we sample $\theta^{(s)} \sim p(\theta | x_i)$ from the posterior distribution and then a new value, and then sample $\tilde{x_i} \sim p(x| \theta^{(s)})$. This represents a new predicted data point for athlete $i$ using the posterior distribution, a common practice for estimating values from a posterior predictive distribution in Bayesian Monte Carlo Simulations (Hoff, 2009). Thus, given we can simulate an athlete's scores, we can then simulate a competition between all candidate athletes and allocate gold, silver, and bronze medals to the top three athletes. 

#### Prior Distribution Creation:

We began by creating prior distributions for each apparatus' total score. Splitting the data set by apparatus and gender resulted in multiple separate smaller data sets, see Exploratory Data Visualizations for the apparatus-gender level distribution. Observing the combined score distributions, they appear to be unimodal and slightly right-skewed. Various distributions were considered, like the beta distribution which is conveniently upper and lower-bounded, but the normal distribution was chosen for its simplicity, ease of use, and effective fit.

** include graphs of fitting normal and beta distributions **

For ease of use, we depended on conjugacy to derive the parameters of the normal distribution. Since both the mean, $mu$, and variance, $sigma^2$, of the normal distribution are unknown, we used normal-inverse gamma priors for both parameters. To estimate prior parameters, we fit a normal distribution to the distribution of athletes' means from the data using the maximum likelihood method and the `fitdist()` function (Muller, 2023). The maximum likelihood estimates for the mean and variance were then used as the prior parameters for the normal part of the normal-inverse gamma distribution. Similarly, for the inverse-gamma parameters, we fit an inverse-gamma distribution to the distribution of athlete's variances from the data using a similar method and used these parameters as the prior parameters for the inverse-gamma part of the normal-inverse gamma distribution. This process was done independently for all apparatus-gender combinations to produce a different set of prior parameters for each independently.

** Include plot of distribution of score means and variances for a chosen apparatus **

### Conditioning on Individual Results:

Following the establishment of the prior distributions, we updated these distributions based on individual competition results. We rely on existing literature for the formulas for the posterior parameters (Hoff, 2009). We then employ a Monte Carlo method to sample new data, simulating the posterior parameters 1000 times per athlete.

### Simulation of Gymnastics Events:

To simulate gymnastics events, we performed 500 iterations for each apparatus event. For every iteration, we simulated a score for each athlete in the event by sampling $\tilde{x_i}$ from the posterior distribution. Furthermore, since the normal distribution is unbounded, we truncated the distribution at 0 and 20 to reflect the scoring system. We then ranked the athletes by their simulated scores and awarded gold, silver, and bronze medals to the top three athletes. Notably, we chose not to go with a qualification structure and had a simple one-shot round for victory. This decision was made due to computational constraints and introduced more variance in the medal distribution, which we take into account when identifying which athletes to pick for Team USA. We repeated the simulation process for each apparatus event, resulting in about 11 million simulated scores across all competitions. 

### Assumptions:

Inherent in our methodology are several assumptions. Firstly, we assume that gymnastic scores are normally distributed, justifying the use of the normal distribution for both prior and posterior distributions. Additionally, we assume independence between events, allowing us to treat each apparatus event as a separate and identically distributed random variable. We also assumed that athletes prioritize all stages of every event identically. Furthermore, we assume that historical performance data adequately represents the gymnasts' true abilities and that changing age is not a factor in gymnastic ability. While this assumption simplifies the modeling process, it may not fully capture the complexities of individual development and improvements over time.

Citations
Muller, Marie Laure Delignette, and Christophe Dutang. “Overview of the Fitdistrplus Package.” R-Project, CRAN, 25 Apr. 2023, cran.r-project.org/web/packages/fitdistrplus/vignettes/fitdistrplus_vignette.html. 

Hoff, Peter D. A First Course in Bayesian Statistical Methods. Springer, 2009.

## Reading data

```{r data}
data_23 = read.csv("Cleaned Data/modified_2023.csv") %>%
  mutate(Apparatus = toupper(Apparatus))
data_21 = read.csv("Cleaned Data/data_2017_2021.csv") 
```

## EDA

```{r}
# Plotting distributions of total scores
data_23 %>%
  ggplot(aes(x = Score, fill = Apparatus)) +
  geom_histogram() +
  labs(title = "Distribution of Total Scores",
       x = "Score",
       y = "Count") +
  facet_wrap(~Apparatus)
```

```{r}
# Plotting distributions of total scores without penalties
data_23 %>%
  ggplot(aes(x = D_Score + E_Score, fill = Apparatus)) +
  geom_histogram() +
  labs(title = "Distribution of Scores before penalties",
       x = "Difficulty + Execution Score",
       y = "Count") +
  facet_wrap(~Apparatus)
```

```{r}
# Plotting distributions of penalties
data_23 %>%
  mutate(Penalty = ifelse(is.na(Penalty), 0, Penalty)) %>%
  ggplot(aes(x = Penalty, fill = Apparatus)) +
  geom_histogram() +
  labs(title = "Distribution of Scores before penalties",
       x = "Difficulty + Execution Score",
       y = "Count") +
  facet_wrap(~Apparatus)
```

```{r}
# Plotting distributions of difficulty scores
data_23 %>%
  ggplot(aes(x = D_Score, fill = Apparatus)) +
  geom_histogram() +
  labs(title = "Distribution of Difficulty Scores",
       x = "Difficulty Score",
       y = "Count") +
  facet_wrap(~Apparatus)
```


```{r}
# Plotting distributions of execution scores
data_23 %>%
  ggplot(aes(x = E_Score, fill = Apparatus)) +
  geom_histogram() +
  labs(title = "Distribution of Execution Scores",
       x = "Execution Score",
       y = "Count") +
  facet_wrap(~Apparatus)
```

Its clear that the execution scores have a left tail to them while the execution scores are more unimodal. Although it doesn't seem like the difficulty scores are exactly normal, they are more normal than the execution scores. 

```{r}
calculate_p_value <- function(estimate, se, null_value = 0) {
  z <- (estimate - null_value) / se
  p_value <- 2 * pnorm(-abs(z))
  return(p_value)
}
```

```{r}
# Running fitdist() on normal dist and calculating p-value
normal_fit = fitdist(data_23$D_Score[data_23$Apparatus == "HB"], "norm")
summary(normal_fit)
calculate_p_value(normal_fit$estimate[[1]], normal_fit$estimate[[2]])

# Compare this to the sample mean and standard deviation
mean(data_23$D_Score[data_23$Apparatus == "HB"])
sd(data_23$D_Score[data_23$Apparatus == "HB"])
```

p-values seem really low, so we can plot this distribution over the data to see how it looks

```{r}
# Plot of the normal distribution over the plot of Apparatus == HB D_Score data
data_23 %>%
  filter(Apparatus == "HB") %>%
  ggplot(aes(x = D_Score)) +
  geom_density() +
  stat_function(fun = dnorm, args = list(normal_fit$estimate[[1]], normal_fit$estimate[[2]]), color = "red", size = 1) +
  labs(title = paste("HB Difficulty compared to normal distribution"),  
       x = "Difficulty Score",
       y = "Density")
```

Looks like a really good fit, but this has me wondering whether when calculating the posterior distribution, should we consider both the mean and the standard deviation to be known values?

## Creating Priors

```{r}
# Loop through all people who have done HB and calculate the standard deviations of their difficulty scores
HB_sd = data_23 %>%
  filter(Apparatus == "HB") %>%
  group_by(FirstName, LastName) %>%
  summarise(sd = sd(D_Score)) %>%
  mutate(sd = ifelse(is.na(sd), 0, sd))

summary(HB_sd$sd)

# Plot histogram of SDs
HB_sd %>%
  filter(sd > 0) %>%
  ggplot(aes(x = sd)) +
  geom_histogram() +
  labs(title = "Distribution of Sigmas of Difficulty Scores",
       x = "Variance",
       y = "Count") + 
  geom_vline(xintercept = mean(HB_sd$sd), color = "red")
```

It seems like the standard deviations themselves follow an inv-gamma distribution, canonically the conjugate prior would be an inverse-gamma but I'm not sure how to approach that and it feels like it would be really complicated to have two prior distributions for difficulty score every apparatus for both genders. I also forgot if I should build the prior from the distribution of means/standard deviations or from the distribution of actual scores

```{r}
# Loop through all people who have done HB and calculate the mean of their difficulty scores
HB_mu = data_23 %>%
  filter(Apparatus == "HB") %>%
  group_by(FirstName, LastName, Gender, Country) %>%
  summarise(mu = mean(D_Score))

# Plot histogram of means
HB_mu %>%
  ggplot(aes(x = mu)) +
  geom_histogram() +
  labs(title = "Distribution of Means of Difficulty Scores",
       x = "Mean",
       y = "Count") + 
  geom_vline(xintercept = mean(HB_mu$mu), color = "red")
```

I think the reason the mean looks so weird is because some athletes get sampled more than others, i don't care though. I'm going to fit a normal distribution to the means and an inv gamma distribution to the SDs and use those as priors

```{r}
normal_mu_fit = fitdist(HB_mu$mu, "norm")
invgamma_sd_fit = fitdist(HB_sd$sd[HB_sd$sd > 0], "invgamma")
```

```{r}
# Plot of the invgamma distribution over the plot HB sd scores
HB_sd %>%
  filter(sd > 0) %>%
  ggplot(aes(x = sd)) +
  geom_density() +
  stat_function(fun = dinvgamma, args = list(shape = invgamma_sd_fit$estimate[[1]],scale = invgamma_sd_fit$estimate[[2]]), color = "red", size = 1) +
  labs(title = paste("HB SD of difficulty scores compared to fitted invgamma distribution"),  
       x = "Difficulty Score",
       y = "Density")
```

## Creating Posteriors

```{r}
smc = 1000
m_0 =  normal_mu_fit$estimate[[1]]
sig_0 = normal_mu_fit$estimate[[2]]
k_0 = invgamma_sd_fit$estimate[[1]] 
v_0 = invgamma_sd_fit$estimate[[2]]

analyze_athlete = function(athlete_results, m_0, sig_0, k_0, v_0, smc) {
  n = length(athlete_results)
  ybar = mean(athlete_results)
  
  if (is.na(var(athlete_results))) {
    var = 0
  } else {
    var = var(athlete_results) 
  }
  
  k_n = k_0 + n
  v_n = v_0 + n
  m_n = (k_0*m_0 + n*ybar)/k_n
  sig_n = (v_0*sig_0 + (n-1)*var + k_0*n*(ybar - m_0)**2/k_n)/v_n
  sig_sample = mean(rinvgamma(smc, v_n/2, sig_n*v_n/2))
  theta_sample = mean(rnorm(smc, m_n, sqrt(sig_sample/k_n)))
  
  return(c(theta_sample, sig_sample))
}
```

```{r}
simul_data = data_23 %>%
  filter(Apparatus == "HB") %>%
  group_by(FirstName, LastName) %>%
  summarise(mean_estimate = analyze_athlete(D_Score, m_0 = m_0, sig_0 = sig_0, k_0 = k_0, v_0 = v_0, smc = 1000)[1],
            sd_estimate = analyze_athlete(D_Score, m_0 = m_0, sig_0 = sig_0, k_0 = k_0, v_0 = v_0, smc = 1000)[2],
            observations = n()) %>%
  rowwise() %>%
  mutate(simulated_D_Score = rnorm(1, mean_estimate, sd_estimate))

simul_data %>%
  ggplot(aes(x = simulated_D_Score)) +
    geom_density(color = "red") +
    labs(title = "simulated d scores",  
         x = "Difficulty Score",
         y = "Density")
```

```{r}
data_23 %>%
  filter(Apparatus == "HB") %>% 
  group_by(FirstName, LastName) %>%
  summarise(mean_d_score = mean(D_Score),
            observations = n()) %>%
  filter(observations > 1) %>%
  inner_join(simul_data, by = c("FirstName", "LastName")) %>%
  ggplot() +
    geom_density(aes(x = mean_d_score), color = "blue") +
    geom_density(aes(x = simulated_D_Score), color = "red") +
    labs(title = "actual d scores vs simulated d scores",
         subtitle = "blue = actual, red = simulated",
         x = "Difficulty Score",
         y = "Density")
```
